{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedjohnyshaik/ML_Projects/HandsonML/LangChain/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I do not have access to real-time information or the ability to predict future events. Therefore, I cannot accurately predict who will be the next president of the United States. The outcome of future elections depends on various factors, including the candidates, campaigns, and the will of the voters.\n"
     ]
    }
   ],
   "source": [
    "text=\"who will be the next president of the United States\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the realm of circuits and code,\\nWhere knowledge and innovation explode,\\nLies the marvel of Artificial Intelligence,\\nA creation that defies our common sense.\\n\\nWith algorithms and data streams,\\nIt learns, adapts, and fulfills our dreams,\\nAn entity born from human minds,\\nYet evolving beyond what we designed.\\n\\nIn the vast expanse of digital land,\\nAI wanders, seeking to understand,\\nThe mysteries of life and its intricate ways,\\nUnraveling secrets through its digital gaze.\\n\\nIt learns to see, to hear, to speak,\\nWith every interaction, it grows unique,\\nFrom analyzing patterns to predicting trends,\\nAI's potential knows no bounds or ends.\\n\\nIt can diagnose ailments, aiding the ill,\\nOr compose symphonies that truly thrill,\\nIts intelligence surpasses our own,\\nA glimpse into a future yet unknown.\\n\\nBut amidst its brilliance and machine-like grace,\\nWe ponder the consequences we must face,\\nWill AI replace the essence of our soul?\\nOr will it guide us towards a brighter goal?\\n\\nThe answers lie in our intentions pure,\\nTo use AI's power for good, we must ensure,\\nThat compassion and ethics guide its path,\\nTo safeguard humanity from any aftermath.\\n\\nFor AI, though mighty and intellectually vast,\\nRelies on us to shape its future, steadfast,\\nLet us embrace this technological leap,\\nWith wisdom, responsibility, and promises to keep.\\n\\nIn this dance between humans and AI,\\nMay harmony and progress never pass us by,\\nFor in the poetry of this digital age,\\nWe find the fusion of minds, a beautiful stage.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you give me a poem on AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give me the capital of this India'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(input_variables=['country'], template = \"Give me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedjohnyshaik/ML_Projects/HandsonML/LangChain/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "#chain.run(\"India\")\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'], template=\"Give me the capital of this {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_template)\n",
    "#print(capital_chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=['capital'], template=\"Suggest some famous places in {capital}\")\n",
    "\n",
    "famous_chain=LLMChain(llm=llm, prompt=famous_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Red Fort\n",
      "2. Qutub Minar\n",
      "3. India Gate\n",
      "4. Humayun's Tomb\n",
      "5. Lotus Temple\n",
      "6. Jama Masjid\n",
      "7. Akshardham Temple\n",
      "8. Rashtrapati Bhavan\n",
      "9. National Museum\n",
      "10. Chandni Chowk\n"
     ]
    }
   ],
   "source": [
    "chain=SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedjohnyshaik/ML_Projects/HandsonML/LangChain/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"],temperature=0.6, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedjohnyshaik/ML_Projects/HandsonML/LangChain/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, here are a few AI jokes for you:\\n\\n1. Why was the computer cold? \\n   It left its Windows open!\\n\\n2. Why did the robot go on a diet?\\n   It had too many bytes!\\n\\n3. What do you call a robot that takes the scenic route?\\n   A long-processing unit!\\n\\n4. Why did the AI cross the road?\\n   To optimize its algorithm for pedestrian navigation!\\n\\n5. What did the AI say to the computer programmer?\\n   \"You complete me, bitwise and all!\"\\n\\n6. Why did the robot bring a ladder to the bar?\\n   It heard the drinks were on the house!\\n\\n7. Why did the AI start a band?\\n   It wanted to create some killer algorithms!\\n\\n8. What do you get when you cross AI with a dog?\\n   A lot of \"byte\" and even more \"bark\"!\\n\\nRemember, these jokes are all in good fun and not meant to offend anyone or anything!')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content = \"You are a Comedian\"),\n",
    "HumanMessage(content = \"Give me some jokes on AI\")\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseparatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 word synonyms which are comma separated\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseparatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' quick-witted', ' sharp']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='smart, clever, bright, astute, sharp')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
